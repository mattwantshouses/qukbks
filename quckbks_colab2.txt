# Quckbks_colab2 Script
# Version 0.1.5

import os
import re
import pandas as pd
import csv
from google.colab import files
import datetime
import io
import chardet
from typing import List, Tuple, Dict, Optional, Union
import logging
from pathlib import Path

# Set up logging
log_folder = Path("logs")
log_folder.mkdir(exist_ok=True)
log_filename = f"logging{datetime.datetime.now().strftime('%m%d%y-%H%M')}.log"
logging.basicConfig(filename=log_folder / log_filename, level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')

# 1. File Selection
def select_files() -> List[str]:
    logging.info("Starting file selection process")
    # 1.1 Display available files
    print("Available files in the Colab environment:")
    file_list: List[str] = os.listdir()
    for i, file in enumerate(file_list, 1):
        print(f"{i}. {file}")
    
    # 1.2 User input for file selection with input validation
    while True:
        print("\nEnter file numbers to process (e.g., '1-3, 5, 7-9') or type 'upload' to add new files:")
        selection: str = input().lower().strip()
        
        if selection == 'upload':
            break
        
        if not re.match(r'^[\d,\s-]+$', selection):
            print("Invalid input. Please use only numbers, commas, hyphens, and spaces.")
            continue
        
        try:
            selected_indices = []
            for part in re.split(r'[;,]\s*', selection):
                if '-' in part:
                    start, end = map(int, part.split('-'))
                    if start < 1 or end > len(file_list) or start > end:
                        raise ValueError
                    selected_indices.extend(range(start-1, end))
                else:
                    index = int(part) - 1
                    if index < 0 or index >= len(file_list):
                        raise ValueError
                    selected_indices.append(index)
            break
        except ValueError:
            print("Invalid input. Please ensure all numbers are within the valid range.")
    
    # 1.3 File upload option
    if selection == 'upload':
        logging.info("User chose to upload new files")
        uploaded: Dict[str, bytes] = files.upload()
        file_list.extend(uploaded.keys())
        print("Updated file list:")
        for i, file in enumerate(file_list, 1):
            print(f"{i}. {file}")
        
        # Repeat file selection process after upload
        while True:
            print("\nEnter file numbers to process (e.g., '1-3, 5, 7-9'):")
            selection = input().strip()
            
            if not re.match(r'^[\d,\s-]+$', selection):
                print("Invalid input. Please use only numbers, commas, hyphens, and spaces.")
                continue
            
            try:
                selected_indices = []
                for part in re.split(r'[;,]\s*', selection):
                    if '-' in part:
                        start, end = map(int, part.split('-'))
                        if start < 1 or end > len(file_list) or start > end:
                            raise ValueError
                        selected_indices.extend(range(start-1, end))
                    else:
                        index = int(part) - 1
                        if index < 0 or index >= len(file_list):
                            raise ValueError
                        selected_indices.append(index)
                break
            except ValueError:
                print("Invalid input. Please ensure all numbers are within the valid range.")
    
    # 1.4 Process user selection
    selected_files: List[str] = [file_list[i] for i in selected_indices]
    
    logging.info(f"Selected files: {', '.join(selected_files)}")
    return selected_files

# 2. Entity Identification
def identify_entity(filename: str) -> Tuple[Optional[str], Optional[str]]:
    logging.info(f"Identifying entity for file: {filename}")
    # 2.1 Define entity mappings
    entities: Dict[str, str] = {
        "Corporate1": "C1",
        "Corporate2": "C2",
        "Corporate3": "C3",
        "Personal": "P",
        "BOA": "BOA",
        "VyStar": "VS"
    }
    # 2.2 Match filename to entity
    for entity, abbr in entities.items():
        if entity.lower() in filename.lower():
            logging.info(f"Entity identified: {entity} ({abbr})")
            return entity, abbr
    logging.warning(f"No entity identified for file: {filename}")
    return None, None

# 3. File Encoding Detection
def detect_encoding(file: str) -> str:
    logging.info(f"Detecting encoding for file: {file}")
    # 3.1 Read file and detect encoding
    with open(file, 'rb') as f:
        raw: bytes = f.read()
    encoding = chardet.detect(raw)['encoding']
    logging.info(f"Detected encoding: {encoding}")
    return encoding

# 4. File Parsing
def parse_file(file: str) -> pd.DataFrame:
    logging.info(f"Parsing file: {file}")
    # 4.1 Determine file type and encoding
    _, ext = os.path.splitext(file)
    encoding: str = detect_encoding(file)

    # 4.2 Parse CSV or TXT files
    if ext.lower() in ['.csv', '.txt']:
        with open(file, 'r', encoding=encoding) as f:
            sample: str = f.read(1024)
        sniffer: csv.Sniffer = csv.Sniffer()
        has_header: bool = sniffer.has_header(sample)
        dialect: csv.Dialect = sniffer.sniff(sample)
        
        with open(file, 'r', encoding=encoding) as f:
            df: pd.DataFrame = pd.read_csv(f, dialect=dialect, header=0 if has_header else None)
    # 4.3 Parse Excel files
    elif ext.lower() in ['.xls', '.xlsx']:
        df = pd.read_excel(file)
    # 4.4 Handle PDF files (not implemented)
    elif ext.lower() == '.pdf':
        # Placeholder for PDF parsing logic
        logging.error("PDF parsing is not yet implemented")
        raise NotImplementedError("PDF parsing is not yet implemented")
    # 4.5 Handle unsupported file types
    else:
        logging.error(f"Unsupported file type: {ext}")
        raise ValueError(f"Unsupported file type: {ext}")
    
    # 4.6 Detect and rename columns
    df = detect_and_rename_columns(df)
    
    logging.info(f"File parsed successfully. Shape: {df.shape}")
    return df

# 5. Column Detection and Renaming
def detect_and_rename_columns(df: pd.DataFrame) -> pd.DataFrame:
    logging.info("Detecting and renaming columns")
    # 5.1 Define column patterns
    column_patterns: Dict[str, str] = {
        'Date': r'(?i)date|time',
        'Description': r'(?i)description|memo|narration',
        'Amount': r'(?i)amount|sum|total',
        'Type': r'(?i)type|category',
        'Balance': r'(?i)balance|remaining'
    }

    # 5.2 Rename columns based on patterns
    for target_col, pattern in column_patterns.items():
        matching_cols: pd.Index = df.columns[df.columns.str.contains(pattern, regex=True)]
        if not matching_cols.empty:
            df = df.rename(columns={matching_cols[0]: target_col})
            logging.info(f"Renamed column to {target_col}")

    return df

# 6. Transaction Classification
def classify_transactions(df: pd.DataFrame) -> pd.DataFrame:
    logging.info("Classifying transactions")
    # 6.1 Define classification function
    def classify(description: str, amount: float) -> str:
        description = description.lower()
        if 'salary' in description or 'payroll' in description:
            return 'Income:Salary'
        elif 'rent' in description:
            return 'Expense:Rent'
        elif 'grocery' in description or 'supermarket' in description:
            return 'Expense:Groceries'
        elif 'restaurant' in description or 'dining' in description:
            return 'Expense:Dining'
        elif 'transfer' in description:
            return 'Transfer'
        elif amount > 0:
            return 'Income:Other'
        else:
            return 'Expense:Other'

    # 6.2 Apply classification to dataframe
    df['Category'] = df.apply(lambda row: classify(row['Description'], row['Amount']), axis=1)
    logging.info("Transactions classified")
    return df

# 7. Transaction Processing
def process_transaction(ledger: pd.DataFrame, date: Union[str, datetime.date], description: str, debit_account: str, credit_account: str, amount: float) -> pd.DataFrame:
    logging.info(f"Processing transaction: {description}, Amount: {amount}")
    # 7.1 Add debit entry
    debit_entry: pd.DataFrame = pd.DataFrame({
        'Date': [date],
        'Description': [description],
        'Account': [debit_account],
        'Debit': [abs(amount)],
        'Credit': [0]
    })
    # 7.2 Add credit entry
    credit_entry: pd.DataFrame = pd.DataFrame({
        'Date': [date],
        'Description': [description],
        'Account': [credit_account],
        'Debit': [0],
        'Credit': [abs(amount)]
    })
    return pd.concat([ledger, debit_entry, credit_entry], ignore_index=True)

# 8. Helper Column Addition
def add_helper_columns(df: pd.DataFrame) -> pd.DataFrame:
    logging.info("Adding helper columns")
    # 8.1 Flag large transactions
    df['Large Transaction'] = df['Amount'].abs() > 10000
    # 8.2 Flag transactions needing review
    df['Needs Review'] = (df['Category'] == 'Expense:Other') | (df['Category'] == 'Income:Other')
    # 8.3 Flag possible duplicates
    df['Possible Duplicate'] = df.duplicated(subset=['Date', 'Amount', 'Description'], keep=False)
    logging.info("Helper columns added")
    return df

# 9. Main Execution
def main() -> None:
    logging.info("Starting Enhanced Financial Data Processor v3.1")
    print("Enhanced Financial Data Processor v3.1")
    selected_files: List[str] = select_files()
    
    entities: Dict[str, Dict[str, Union[str, pd.DataFrame]]] = {}

    # 9.2 Process each selected file
    for file in selected_files:
        logging.info(f"Processing file: {file}")
        print(f"\nProcessing file: {file}")
        entity_name, entity_abbr = identify_entity(file)
        if entity_name is None:
            while True:
                print(f"Unable to identify entity for {file}. Please enter the entity name:")
                entity_name = input().strip()
                if entity_name:
                    entity_abbr = entity_name[:2].upper()
                    logging.info(f"User provided entity name: {entity_name}")
                    break
                else:
                    print("Entity name cannot be empty. Please try again.")

        # 9.3 Initialize entity data structure
        if entity_name not in entities:
            entities[entity_name] = {
                'name': entity_name,
                'abbr': entity_abbr,
                'coa': ChartOfAccounts(),
                'ledger': pd.DataFrame(columns=['Date', 'Description', 'Account', 'Debit', 'Credit']),
                'transactions': pd.DataFrame()
            }
            logging.info(f"Initialized data structure for entity: {entity_name}")
        
        # 9.4 Process file and handle errors
        try:
            df: pd.DataFrame = parse_file(file)
            df = classify_transactions(df)
            df = add_helper_columns(df)
            entities[entity_name]['transactions'] = pd.concat([entities[entity_name]['transactions'], df], ignore_index=True)
            logging.info(f"File processed successfully. Shape: {df.shape}")
            print(f"Successfully processed file. Shape: {df.shape}")
            print(df.head())

            # 9.5 Process transactions into ledger
            for _, row in df.iterrows():
                entities[entity_name]['ledger'] = process_transaction(
                    entities[entity_name]['ledger'],
                    row['Date'],
                    row['Description'],
                    row['Category'],
                    'Assets:Cash' if row['Amount'] < 0 else 'Income:Unknown',
                    abs(row['Amount'])
                )

            # 9.6 Generate and export reports
            export_chart_of_accounts(entity_abbr, entities[entity_name]['coa'])
            pl_df: pd.DataFrame = generate_profit_and_loss(entities[entity_name]['ledger'], df['Date'].min(), df['Date'].max())
            export_profit_and_loss(entity_abbr, pl_df)
            logging.info(f"Reports generated and exported for entity: {entity_name}")

        except FileNotFoundError as e:
            logging.error(f"Error processing {file}: File not found. Details: {str(e)}")
            print(f"Error processing {file}: File not found. Details: {str(e)}")
        except pd.errors.EmptyDataError as e:
            logging.error(f"Error processing {file}: The file is empty. Details: {str(e)}")
            print(f"Error processing {file}: The file is empty. Details: {str(e)}")
        except pd.errors.ParserError as e:
            logging.error(f"Error processing {file}: Unable to parse the file. Details: {str(e)}")
            print(f"Error processing {file}: Unable to parse the file. Details: {str(e)}")
        except ValueError as e:
            logging.error(f"Error processing {file}: Invalid data in the file. Details: {str(e)}")
            print(f"Error processing {file}: Invalid data in the file. Details: {str(e)}")
        except KeyError as e:
            logging.error(f"Error processing {file}: Missing required column. Details: {str(e)}")
            print(f"Error processing {file}: Missing required column. Details: {str(e)}")
        except Exception as e:
            logging.error(f"Unexpected error processing {file}: {type(e).__name__}. Details: {str(e)}")
            print(f"Unexpected error processing {file}: {type(e).__name__}. Details: {str(e)}")
        
        while True:
            print("Do you want to skip this file and continue with the next one? (y/n)")
            choice: str = input().lower().strip()
            if choice in ['y', 'n']:
                break
            print("Invalid input. Please enter 'y' or 'n'.")
        
        if choice == 'n':
            logging.info("User chose to abort processing")
            print("Aborting processing. Please fix the issue and run the script again.")
            return

    # 9.7 Print processing summary
    logging.info("Processing complete. Generating summary.")
    print("\nProcessing complete. Summary:")
    for entity_name, entity_data in entities.items():
        print(f"\n{entity_name}:")
        print(f"Total transactions: {len(entity_data['transactions'])}")
        if not entity_data['transactions'].empty:
            print(f"Date range: {entity_data['transactions']['Date'].min()} to {entity_data['transactions']['Date'].max()}")
            print(f"Total amount: {entity_data['transactions']['Amount'].sum():.2f}")
        else:
            print("No transactions processed for this entity.")
        logging.info(f"Summary for {entity_name}: {len(entity_data['transactions'])} transactions processed")

    logging.info("Script execution completed")

if __name__ == "__main__":
    main()